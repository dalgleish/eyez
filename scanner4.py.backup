#!/usr/bin/env python

import seeed_mlx9064x
import numpy as np
import cv2
import time
import os
import signal
import sys
import pigpio
import threading

def signal_handler(sig, frame):
    cleanup()
    sys.exit(0)

signal.signal(signal.SIGINT, signal_handler)

# in the detect_person function, the threshold is used to decide how much of a temperature difference 
# between the background and the current frame is significant enough to be considered as part of a person, 
# rather than just noise or minor fluctuations.

#     Threshold Calculation: The cv2.threshold function compares each pixel's value in the diff image 
#     (which represents the difference between the current frame and the background). 
#     If the pixel's value is higher than the given threshold, it is turned into white (255 in grayscale), 
#     meaning "this is significant". If it's lower, it's turned into black (0 in grayscale), meaning "this is not significant".

#     Binary Image Creation: This creates a binary image (thresh) where all pixels representing 
#     significant differences are white, 
#     and all other pixels are black. This helps isolate the areas of the frame that have changed 
#     significantly, which usually corresponds to where the person is.

#     Noise Reduction: Setting an appropriate threshold helps reduce noise. 
#     If the threshold is too low, minor temperature changes might be mistaken for movement, leading to false detections. 
#     If the threshold is too high, you might miss detecting parts of the person, especially if the temperature difference isn't very pronounced.

# By adjusting the threshold, you balance sensitivity to temperature changes and noise reduction. 
# Itâ€™s like a filter that tunes out the irrelevant fluctuations and highlights the meaningful 
# changes that signify the presence of a person.
threshold = 25


# output images and stich together a video for debugging
make_video = False

pwm = None

# RIGHT EYE
# GPIO pin for PWM with 50Hz
right_servo = 18
left_servo = 12

quadrants = {
    # Right Eye Range
    # 32 possible columns
    # ~60 pulse widths between 600 and 2500 for standard servo
    right_servo: [60 * i + 600 for i in range(32)],
    # Right Eye Range
    # 32 possible columns
    # ~60 pulse widths between 600 and 2500 for standard servo
    left_servo: [60 * i + 600 for i in range(32)],
}

def translate_to_quadrant(column, servo):
    if column is None:
        return

    return quadrants[servo][int(column)]

def cleanup():
    print("Cleaning up...")

    if pwm is not None:
        # turning off servos
        pwm.set_PWM_dutycycle(right_servo, 0)
        pwm.set_PWM_frequency(right_servo, 0)
        pwm.set_PWM_dutycycle(left_servo, 0)
        pwm.set_PWM_frequency(left_servo, 0)
    if make_video:
        create_video('frames', 'output_video.avi')
    clear_frames_directory()

def move_servos(pwm, target_column):
    pulse_width_left = translate_to_quadrant(target_column, left_servo)
    pulse_width_right = translate_to_quadrant(target_column, right_servo)

    if pulse_width_left is not None and pulse_width_right is not None:
        pwm.set_servo_pulsewidth(right_servo, pulse_width_right)
        pwm.set_servo_pulsewidth(left_servo, pulse_width_left)
        time.sleep(0.1)
        # turning off servos
        pwm.set_PWM_dutycycle(right_servo, 0)
        pwm.set_PWM_frequency(right_servo, 0)
        pwm.set_PWM_dutycycle(left_servo, 0)
        pwm.set_PWM_frequency(left_servo, 0)


def main():
    
    # START SERVO SETUP ##################
    # more info at http://abyz.me.uk/rpi/pigpio/python.html#set_servo_pulsewidth
    pwm = pigpio.pi()
    pwm.set_mode(right_servo, pigpio.OUTPUT)
    pwm.set_PWM_frequency(right_servo, 50)

    # pwm = pigpio.pi()
    pwm.set_mode(left_servo, pigpio.OUTPUT)
    pwm.set_PWM_frequency(left_servo, 50)
    # END SERVO SETUP

    mlx = seeed_mlx9064x.grove_mxl90640()
    frame = [0] * 768  # 32x24
    width, height = 32, 24
    # Initialize background model with zeros
    background_model = np.zeros((24, 32), np.uint8)
    mlx.refresh_rate = seeed_mlx9064x.RefreshRate.REFRESH_4_HZ
    time.sleep(1)
    
    # Buffer for smoothing
    buffer_size = 5
    frames_buffer = []
    frame_count = 0
    current_column = 16
    target_column = 16

    while True:
        try:
            start_time = time.time()
            try:
                mlx.getFrame(frame)
            except Exception as e:
                continue

            # Convert frame data to NumPy array and convert to float type
            current_frame = np.array(frame).reshape(height, width).astype(float)
            
            # Normalize data to a fixed range (for speed)
            normalized_data = cv2.normalize(current_frame, None, 0, 255, cv2.NORM_MINMAX)
            normalized_data = np.uint8(normalized_data)

            # Add current frame to buffer
            frames_buffer.append(normalized_data)
            if len(frames_buffer) > buffer_size:
                frames_buffer.pop(0)
            
            # Average frames in buffer for smoothing
            smoothed_frame = np.mean(frames_buffer, axis=0).astype(np.uint8)
            background_model = update_background_model(smoothed_frame, background_model)
            target_column = detect_person(smoothed_frame, background_model)

            # If nothing changed, do nothing
            if target_column is None or current_column == target_column:
                continue

            print('column:', target_column)
            move_servos(pwm, target_column)
            current_column = target_column

            # Save normalized frame
            if make_video:
                save_image(normalized_data, f'frames/normalized_{frame_count}.png')
                frame_count += 1

            # output_fps(start_time)
        except KeyboardInterrupt:
            break


def update_background_model(frame, background_model, alpha=0.05):
    return cv2.addWeighted(frame, alpha, background_model, 1 - alpha, 0)


def detect_person(frame, background_model):
    diff = cv2.absdiff(frame, background_model)

    _, thresh = cv2.threshold(diff, threshold, 255, cv2.THRESH_BINARY)
    kernel = np.ones((5, 5), np.uint8)
    dilated = cv2.dilate(thresh, kernel, iterations=2)
    eroded = cv2.erode(dilated, kernel, iterations=1)
    contours, _ = cv2.findContours(eroded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    if contours:
        largest_contour = max(contours, key=cv2.contourArea)
        x, y, w, h = cv2.boundingRect(largest_contour)
        person_column = x + w // 2
        return person_column

    return None



## DEBUGGING ####################################

def output_fps(start_time):
    # Frames per second
    end_time = time.time()
    fps = 1 / (end_time - start_time)
    print(f'FPS: {fps:.2f}')

def clear_frames_directory(directory='frames/'):
    for filename in os.listdir(directory):
        file_path = os.path.join(directory, filename)
        try:
            if os.path.isfile(file_path) or os.path.islink(file_path):
                os.unlink(file_path)
                print(f'Removed {file_path}')
            elif os.path.isdir(file_path):
                os.rmdir(file_path)
                print(f'Removed directory {file_path}')
        except Exception as e:
            print(f'Failed to delete {file_path}. Reason: {e}')


def save_image(data, filename):
    cv2.imwrite(filename, data)


def create_video(image_folder, output_video, fps=10):
    images = [img for img in os.listdir(image_folder) if img.endswith(".png")]
    frame = cv2.imread(os.path.join(image_folder, images[0]))
    height, width, layers = frame.shape

    video = cv2.VideoWriter(output_video, cv2.VideoWriter_fourcc(*'DIVX'), fps, (width, height))

    for image in images:
        video.write(cv2.imread(os.path.join(image_folder, image)))

    cv2.destroyAllWindows()
    video.release()


## ENTRYPOINT ####################################
if __name__ == '__main__':
    clear_frames_directory()
    main()
